{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary file query speed test in Python\n",
    "\n",
    "Say you want to query the contents of a binary file&mdash;in my case a SIN result file from a SESTRA analysis, but that part is not important. The file has a header with offset tables to tell you the number of rows (records) and the number of columns (fields) for a given matrix (record table). You want to search through the file to find a record that has a certain number in column 4 (index 3). The problem: you cannot guarantee that the matrix will fit in memory.\n",
    "\n",
    "This notebook creates a dummy binary file with an embedded matrix of floats that does not start at the beginning of the file or end at the end of the file, to make the tests a bit more realistic (similar to the SIN file format, but not with multiple matrices and without the offset tables). In the test case the matrix can be held in memory, it is not enormous, but we want to find a way to extract the relatively few records we are interested in, without holding the whole thing in memory. We also want to do this in Python.\n",
    "\n",
    "What follows is:\n",
    "\n",
    "- Creation of the test file along with a verification that it actually works to read it back\n",
    "- Pure Python tests\n",
    "- Numpy tests (some hold the whole matrix in memory just to establish a baseline)\n",
    "- Numpy tests using numexpr to query the matrix. This allows more complicated queries that can still be fast with large matrices\n",
    "\n",
    "Conclusion: chunked reading with numpy combined with numexpr seems to be a good way forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import struct\n",
    "import numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 362869, 1111553, 1408003, 3442858, 4693057, 6975679, 8670366, 8711933, 9209097, 9922566, 9999999]\n",
      "b'ABCDEFGHIJ'\n",
      "(1.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "(10000000.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "b'THEEND!FIN'\n"
     ]
    }
   ],
   "source": [
    "def make_data(N, M, filename, header, footer, Nind):\n",
    "    \"\"\"\n",
    "    Make a binary file with an array of records in between a header and a footer\n",
    "    \"\"\"\n",
    "    data = numpy.zeros((N, M), dtype=numpy.float32)\n",
    "    \n",
    "    ind = [0] + sorted(numpy.random.randint(0, N, Nind - 2)) + [N-1]\n",
    "    data[:,0] = numpy.arange(N) + 1\n",
    "    data[ind,3] = 42.0\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(header.encode('ASCII'))\n",
    "        data.tofile(f)\n",
    "        f.write(footer.encode('ASCII'))\n",
    "    \n",
    "    return ind\n",
    "\n",
    "header = 'ABCDEFGHIJ'\n",
    "footer = 'THEEND!FIN'\n",
    "N = 1000_0000\n",
    "M = 10\n",
    "offset = len(header)\n",
    "filename = os.path.expanduser('~/DELETEME.bin')\n",
    "\n",
    "\n",
    "# Make the dummy data\n",
    "ind0 = make_data(N, M, filename, header, footer, Nind=12)\n",
    "print(ind0)\n",
    "\n",
    "def verify(filename, N, M, offset):\n",
    "    \"\"\"\n",
    "    Reade the file just to see that the data is readable\n",
    "    and that the format is as expected\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read header\n",
    "        print(f.read(offset))\n",
    "        \n",
    "        # Read first record\n",
    "        rec1 = f.read(M * 4)\n",
    "        print(struct.unpack('%df' % M, rec1))\n",
    "        \n",
    "        # Read second record\n",
    "        rec2 = f.read(M * 4)\n",
    "        print(struct.unpack('%df' % M, rec2))\n",
    "        \n",
    "        # Read last record\n",
    "        f.seek(offset + (N - 1) * M * 4)\n",
    "        recN = f.read(M * 4)\n",
    "        print(struct.unpack('%df' % M, recN))\n",
    "        \n",
    "        # Read footer\n",
    "        print(f.read(offset))\n",
    "\n",
    "verify(filename, N, M, offset)\n",
    "\n",
    "def is_ok(ind):\n",
    "    diff = numpy.array(ind) - numpy.array(ind0)\n",
    "    return (diff == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.13 s ± 103 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def read_one_by_one(filename, N, M, offset):\n",
    "    \"\"\"\n",
    "    Pure Python: read one record a a time\n",
    "    \"\"\"\n",
    "    ind = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        f.seek(offset)\n",
    "        for _ in range(N):\n",
    "            rec = f.read(M * 4)\n",
    "            values = struct.unpack('%df' % M, rec)\n",
    "            if values[3] > 0:\n",
    "                ind.append(int(values[0]))\n",
    "    assert is_ok(ind)\n",
    "\n",
    "%timeit -n1 -r3 read_one_by_one(filename, N, M, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.02 s ± 246 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def read_chunked(filename, N, M, offset, chunksize):\n",
    "    \"\"\"\n",
    "    Pure Python: read the file in chunks to reduce the number of read() calls\n",
    "    \"\"\"\n",
    "    ind = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        f.seek(offset)\n",
    "        count = 0\n",
    "        while count < N:\n",
    "            Q = min(chunksize, N - count)\n",
    "            count += chunksize\n",
    "            data = f.read(Q * M * 4)\n",
    "            for i in range(Q):\n",
    "                rec = data[i * M * 4 : (i + 1) * M * 4]\n",
    "                values = struct.unpack('%df' % M, rec)\n",
    "                if values[3] > 0:\n",
    "                    ind.append(int(values[0]))\n",
    "    assert is_ok(ind)\n",
    "\n",
    "%timeit -n1 -r3 read_chunked(filename, N, M, offset, 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2 s ± 143 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def read_numpy(filename, N, M, offset):\n",
    "    \"\"\"\n",
    "    Read the whole file into a numpy matrix, query in a Python loop\n",
    "    \"\"\"\n",
    "    ind = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        f.seek(offset)\n",
    "        arr = numpy.fromfile(f, dtype=numpy.float32, count=N*M)\n",
    "        arr = arr.reshape((N, M))\n",
    "        for values in arr:\n",
    "            if values[3] > 0:\n",
    "                ind.append(int(values[0]))\n",
    "    assert is_ok(ind)\n",
    "\n",
    "%timeit -n1 -r3 read_numpy(filename, N, M, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 ms ± 7.25 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def read_numpy2(filename, N, M, offset):\n",
    "    \"\"\"\n",
    "    Read the whole file into a numpy matrix, query using numpy\n",
    "    \"\"\"\n",
    "    ind = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        f.seek(offset)\n",
    "        arr = numpy.fromfile(f, dtype=numpy.float32, count=N*M)\n",
    "        arr = arr.reshape((N, M))\n",
    "        arr2 = arr[arr[:,3] > 0]\n",
    "        ind = arr2[:,0]\n",
    "    assert is_ok(ind)\n",
    "\n",
    "%timeit -n1 -r3 read_numpy2(filename, N, M, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.6 ms ± 5.95 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def read_numpy_chunked(filename, N, M, offset, chunksize):\n",
    "    \"\"\"\n",
    "    Read the file in chunks using numpy, query using numpy\n",
    "    \"\"\"\n",
    "    ind = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        f.seek(offset)\n",
    "        count = 0\n",
    "        while count < N:\n",
    "            Q = min(chunksize, N - count)\n",
    "            count += chunksize\n",
    "            arr = numpy.fromfile(f, dtype=numpy.float32, count=Q*M)\n",
    "            arr = arr.reshape((Q, M))\n",
    "            sieve = arr[:,3] > 0\n",
    "            arr2 = arr[sieve]\n",
    "            ind.extend(arr2[:,0])\n",
    "    assert is_ok(ind)\n",
    "\n",
    "%timeit -n1 -r3 read_numpy_chunked(filename, N, M, offset, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 ms ± 3.68 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def read_numpy_chunked_numexpr(filename, N, M, offset, chunksize):\n",
    "    \"\"\"\n",
    "    Read the file in chunks using numpy, query using numexpr\n",
    "    \"\"\"\n",
    "    ind = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        f.seek(offset)\n",
    "        count = 0\n",
    "        while count < N:\n",
    "            Q = min(chunksize, N - count)\n",
    "            count += chunksize\n",
    "            arr = numpy.fromfile(f, dtype=numpy.float32, count=Q*M)\n",
    "            arr = arr.reshape((Q, M))\n",
    "            variables = {'c%d' % i: arr[:,i] for i in range(M)}\n",
    "            sieve = numexpr.evaluate('c3 > 0', variables)\n",
    "            arr2 = arr[sieve]\n",
    "            ind.extend(arr2[:,0])\n",
    "    assert is_ok(ind)\n",
    "\n",
    "%timeit -n1 -r3 read_numpy_chunked_numexpr(filename, N, M, offset, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.7 s ± 2.25 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def read_numpy_memmap(filename, N, M, offset):\n",
    "    \"\"\"\n",
    "    Read the file in numpy using memmap to avoid holding the whole file in memory\n",
    "    Query using a Python loop\n",
    "    \"\"\"\n",
    "    ind = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        arr = numpy.memmap(f, dtype=numpy.float32, mode='r', shape=(N, M), offset=offset)\n",
    "        for values in arr:\n",
    "            if values[3] > 0:\n",
    "                ind.append(int(values[0]))\n",
    "    assert is_ok(ind)\n",
    "\n",
    "%timeit -n1 -r3 read_numpy_memmap(filename, N, M, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.5 s ± 567 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def read_numpy_memmap2(filename, N, M, offset):\n",
    "    \"\"\"\n",
    "    Read the file in numpy using memmap to avoid holding the whole file in memory\n",
    "    Query using numpy\n",
    "    \"\"\"\n",
    "    ind = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        arr = numpy.memmap(f, dtype=numpy.float32, mode='r', shape=(N, M), offset=offset)\n",
    "        arr2 = arr[arr[:,3] > 0]\n",
    "        ind = arr2[:,0]\n",
    "    assert is_ok(ind)\n",
    "\n",
    "%timeit -n1 -r3 read_numpy_memmap(filename, N, M, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
